# Leituras

## Aula 13 - Embeddings, Transformers e o BERT
___

**Leituras Obrigatórias:**  
- Jurafsky, D. and Martin, J. H. (2024). {cite}`jurafsky2024speech`. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models. 3rd edition. Capitulo 5: Embeddings, Capítulo 8: Transformers e Capítulo 9: Masked Language Models
- VASWANI, Ashish et al. (2017). {cite}`Vaswani2017Attention`. Attention is all you need. In: Advances in Neural Information Processing Systems, p. 5998-6008, 2017.
- DEVLIN, Jacob et al. (2019). {cite}`Devlin2019BERT`. BERT: pre-training of deep bidirectional transformers for language understanding. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), p. 4171-4186, 2019.





**Objetivos da aula:**  
- Introduzir os alunos aos embeddings, chegando nos embeddings contextuais
- Apresentar aos alunos a arquitetura Transformers;
- Apresentar o BERT, um modelo com transformers bidirecionais, que comporta o contexto das palavras;
- Usar o BERTimbau (BERT pré-treinado em português) para a tarefa de classificação


**Leituras Complementares:**

- Géron, Aurelien. (2022). {cite}`geron2022hands`."10. Introduction to Artificial Neural Networks with Keras” and “11. Training Deep Neural Networks” in *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems*.  
- Eli Stevens, Eli; Antiga, Luca; Viehmann, Thomas. (2020). {cite}`stevens2020deep`.Deep Learning with PyTorch: Build, Train, and Tune Neural Networks Using Python Tools. Manning Publications.
- TUNSTALL, Lewis; VON WERRA, Leandro; WOLF, Thomas. {cite}`tunstall2022nlp`. Natural Language Processing with Transformers: Building Language Applications with Hugging Face. Sebastopol, CA: O'Reilly Media, 2022. ISBN 978-1-098-13679-6.



**Laboratório 13: BERTimbau para a Classificação de Texto**  






