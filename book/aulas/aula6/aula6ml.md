# O Problema de Classifica√ß√£o

Na √∫ltima aula, aprofundamos os conceitos fundamentais do aprendizado supervisionado, diferenciando os objetivos de infer√™ncia e predi√ß√£o, e discutindo como construir bancos de dados de treinamento confi√°veis para aplica√ß√µes em PLN. Exploramos o papel dos m√©todos param√©tricos e n√£o-param√©tricos, os principais trade-offs entre flexibilidade e interpretabilidade, e a import√¢ncia de equilibrar vi√©s e vari√¢ncia para obter modelos robustos e generaliz√°veis. Tamb√©m revisamos m√©tricas essenciais para avalia√ß√£o de classificadores e destacamos a necessidade de testar os modelos em dados novos para garantir sua utilidade pr√°tica. Por fim, apresentamos um protocolo padr√£o para conduzir pesquisas rigorosas e transparentes em aprendizado de m√°quina supervisionado.

Na aula de hoje, iremos discutir o problema espec√≠fico de classifica√ß√£o, e alguns dos modelos mais b√°sicos utilizados para esta tarefa. O problema de classifica√ß√£o surge quando temos uma vari√°vel categ√≥rica como nossa vari√°vel resposta $y$. Ou seja, n√£o queremos prever um valor num√©rico cont√≠nuo (e.g. valor de uma casa), mas uma classe (favor√°vel, desfavor√°vel, incerto). Alguns dos classificadores[^1] mais comuns s√£o: Regress√£o Log√≠stica, *Linear Discriminant Analysis* (*LDA*), *Quadratic Discriminant Analysis*, *Naive Bayes* e *K Nearest Neighbors* (KNN). No cap√≠tulo 2, James et al. ({cite}`james2023introduction`.) discutem o KNN, e no cap√≠tulo 4 focam nos outros citados acima.


## Por que n√£o Regress√£o Linear?


Uma quest√£o que pode surgir √© a de por que n√£o usar a regress√£o linear para classifica√ß√£o se podemos colocar as categorias como n√∫meros? Vamos supor o seguinte caso de classifica√ß√£o em tr√™s diagn√≥sticos:

$$
Y =
\begin{cases}
  1 & \text{se AVC;} \\\\
  2 & \text{se Overdose;} \\\\
  3 & \text{se Crise Epil√©ptica.}
\end{cases}
$$

Al√©m de gerar um ordenamento entre os casos (Crise Epil√©ptica ser "maior" que AVC), estabelece que a dist√¢ncia entre um AVC e a overdose √© a mesma que entre uma overdose e uma crise epil√©ptica. Ainda por cima, alterar a ordem dessa categoriza√ß√£o geraria estimativas com significados e dimens√µes muito diferentes, tornando o modelo de regress√£o linear inst√°vel e pouco confi√°vel. A situa√ß√£o melhora um pouco quando temos apenas dois resultados poss√≠veis:


$$
Y =
\begin{cases}
  0 & \text{se AVC;} \\\\
  1 & \text{se Overdose;} \\\\
\end{cases}
$$

Mesmo se alter√°ssemos os valores, os resultados se manteriam. No entanto, poder√≠amos obter valores estimados para al√©m dos limites 0 e 1, al√©m de obter poucas estimativas para casos mais perto dos valores m√°ximos e m√≠nimos, como mostra a seguinte figura:


```{figure} ../aula6/images/fig4.2.a.png
---
width: 100%
name: reglinclass
align: center
---
Classifica√ß√£o no banco "Default" utilizando uma regress√£o linear. Fonte: James et al. ({cite}`james2023introduction`., p. 139)
```

A {numref}`Figura {number} <reglinclass>` mostra que a regress√£o linear (linha azul) concentra a maior parte dos valores estimados de Y (Probabilidade de *Default*) bem perto de zero. Portanto, pouqu√≠ssimos indiv√≠duos seriam classificados como inadimplentes (ou devedores). Al√©m disso, encontramos probabilidades negativas (o que √© imposs√≠vel) perto de valores de *balance* (Saldo do cart√£o de cr√©dito) menores que 500. No laborat√≥rio de hoje exploraremos um pouco mais desse banco de dados apresentado pelos autores, e tentaremos classificar os adimplentes e inadimplentes utilizando os diversos modelos discutidos no cap√≠tulo.

```{admonition} üí¨ Com a palavra, os autores:
:class: quote
"Para resumir, existem pelo menos duas raz√µes para n√£o realizar classifica√ß√£o utilizando um m√©todo de regress√£o [linear]: (a) um m√©todo de regress√£o n√£o pode acomodar uma resposta qualitativa com mais de duas classes; (b) um m√©todo de regress√£o n√£o fornecer√° estimativas significativas de Pr(Y | X), mesmo com apenas duas classes. Assim, √© prefer√≠vel usar um m√©todo de classifica√ß√£o que seja realmente adequado para valores de resposta qualitativa."
({cite}`james2023introduction`., p. 138, tradu√ß√£o nossa)
```

## A Regress√£o Log√≠stica

Quando temos um resultado bin√°rio (Sim ou n√£o, 0 ou 1), podemos utilizar a regress√£o log√≠stica para modelar a probabilidade de que $Y_i$ pertence a determinada categoria.

$$
Pr(Y_i = 1 | X)
$$

Traduzindo, queremos a probabilidade ($Pr$) de que $Y_i$ perten√ßa a categoria 1 dado ($|$) os valores das vari√°veis preditoras associadas √†quela observa√ß√£o ($X$). No caso do banco de inadimplentes (*Default*), podemos querer saber a probabilidade de que um indiv√≠duo vai ser inadimplente dada suas caracter√≠sticas preditoras (Se √© estudante ou n√£o, renda, d√≠vidas anteriores, etc.). No caso da regress√£o log√≠stica simples (de um √∫nico preditor), podemos pensar somente com rela√ß√£o ao saldo (*Balance*) do cart√£o do indiv√≠duo:


$$
Pr(Inadimplente = Sim | Saldo)
$$

Estimando a mesma rela√ß√£o apresentada na {numref}`Figura {number} <reglinclass>` com um modelo de regress√£o log√≠stica, obtemos o seguinte resultado:

```{figure} ../aula6/images/fig4.2.b.png
---
width: 100%
name: reglogclass
align: center
---
Classifica√ß√£o no banco "Default" utilizando uma regress√£o log√≠stica. Fonte: James et al. ({cite}`james2023introduction`., p. 139)
```

A {numref}`Figura {number} <reglogclass>` mostra que temos uma rela√ß√£o muito mais "limpa" entre o saldo de cart√£o de cr√©dito e os valores estimados para a probabilidade de que seja um inadimplente: N√£o possu√≠mos valores negativos na fun√ß√£o estimada (curva azul), e indiv√≠duos com maior saldo de cart√£o tem maior probabilidade de serem classificados como inadimplentes. Para modelar a $Pr(Y_i = 1 | X)$ na regress√£o log√≠stica, ou $p(X)$ para encurtar, precisamos da **Fun√ß√£o Log√≠stica**, uma das fun√ß√µes que permitem um *output* entre zero e um.


### Fun√ß√£o Log√≠stica

Lembrando que $p(x)$ √© equivalente √† $Pr(Y_i = 1 | X)$, podemos estimar a regress√£o log√≠stica utilizando a seguinte **Fun√ß√£o Log√≠stica**

$$
p(X) = \frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}}.
$$

Os par√¢metros $\beta_0$ e $\beta_1$ tamb√©m s√£o estimados, assim como na regress√£o linear. A diferen√ßa est√° em como √© feito. Na regress√£o linear, utilizamos o m√©todo de m√≠nimos quadrados ordin√°rios (ou *OLS* em ingl√™s) para estimar os par√¢metros da equa√ß√£o. Aqui, utilizaremos o m√©todo da M√°xima Verossimilhan√ßa, ou *Maximum Likelihood*, que veremos na pr√≥xima subse√ß√£o (e coloquei um v√≠deo complementar para quem tiver interesse). Com um pouco de manipula√ß√£o (segundo os autores, n√£o eu), chegamos em:

$$
\frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1 X}.
$$

O lado esquerdo da equa√ß√£o ($\frac{p(X)}{1 - p(X)}$) √© conhecido por *odds*, e podem ter qualquer valor entre 0 e $\infty$, e quanto maior, maior a probabilidade de Inadimpl√™ncia (no nosso exemplo anterior), e vice-versa. Tirando o logaritmo de ambos os lados, chegamos em.


$$
\log\!\left(\frac{p(X)}{1 - p(X)}\right) = \beta_0 + \beta_1 X.
$$

Que √© o *log odds* ou *logit*, este √∫ltimo que √© muitas vezes usado como sin√¥nimo de regress√£o log√≠stica. Em um modelo de regress√£o log√≠stica, aumentar $X_1$ em uma unidade altera o valor de *log odds* por $\beta_1$. No entanto a rela√ß√£o entre $p(X)$ e $X$ n√£o √© linear, e o quanto $p(x)$ muda com a mudan√ßa de $X$ depende do valor atual de $X$.


Em resumo, a regress√£o log√≠stica transforma a probabilidade de um evento em uma escala que pode ser modelada linearmente, utilizando o logit (ou log odds) como liga√ß√£o entre as vari√°veis explicativas e o resultado. O modelo estima a rela√ß√£o entre os preditores e a chance de ocorr√™ncia de um evento, garantindo que as previs√µes estejam sempre entre 0 e 1. Essa abordagem √© especialmente √∫til para problemas de classifica√ß√£o bin√°ria, pois permite interpretar diretamente o impacto de cada vari√°vel sobre a probabilidade do evento e evita problemas comuns da regress√£o linear, como previs√µes fora do intervalo v√°lido de probabilidades.



### M√©todo de M√°xima Verossimilhan√ßa

Para estimar os par√¢metros $\beta_0$ e $\beta_1$ na equa√ß√£o
 
$$
p(X) = \frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}}.
$$

√© utilizado o m√©todo de m√°xima verossimilhan√ßa. A intui√ß√£o por tr√°s desse m√©todo √© a de ele procura estimar os par√¢metros $\beta_0$, $\beta_1$,..., $\beta_p$ (para o caso com mais vari√°veis preditoras) tal que a probabilidade $\hat{p}(X_i)$ para cada indiv√≠duo corresponda, da melhor maneira poss√≠vel, √† probabilidade observada $p(x_i)$. Ou seja,


$$
\frac{e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}} = \hat{p}(X_i) \approx p(X_i) 
$$

Para isso, √© utilizada a seguinte fun√ß√£o de verossimilhan√ßa.

$$
\ell(\beta_0, \beta_1)
     = \prod_{i:\,y_i = 1} p(x_i)\;
       \prod_{i':\,y_{i'} = 0} \!\bigl(1 - p(x_{i'})\bigr).
$$

Em palavras simples, a equa√ß√£o afirma: ‚ÄúPara um conjunto de par√¢metros ($\beta_0, \beta_1$), a verossimilhan√ßa √© o produto da probabilidade prevista do evento em todos os casos que de fato ocorreram ($y = 1$) multiplicado pela probabilidade prevista do n√£o-evento em todos os casos que n√£o ocorreram ($y = 0$).‚Äù


Quando as observa√ß√µes s√£o independentes, a verossimilhan√ßa de um modelo √© obtida multiplicando as probabilidades individuais atribu√≠das a cada dado observado. Aqui, p(x·µ¢) representa a probabilidade calculada pelo modelo (por exemplo, a sa√≠da da regress√£o log√≠stica) de que o i-√©simo indiv√≠duo tenha y = 1. Para cada y·µ¢ = 1, inclu√≠mos p(x·µ¢) no produto; para cada y·µ¢ = 0, inclu√≠mos 1 ‚àí p(x·µ¢). Dessa forma, par√¢metros que atribuem alta probabilidade aos resultados realmente vistos tornam o produto ‚Äì e, portanto, a verossimilhan√ßa ‚Äì maior.

A m√°xima verossimilhan√ßa √© uma fun√ß√£o utilizada em muitos modelos param√©tricos n√£o-lineares, e com os coeficientes estimados por ela podemos fazer previs√µes para dados n√£o vistos.

### Regress√£o Log√≠stica M√∫ltipla

A Regress√£o Log√≠stica M√∫ltipla √© a generaliza√ß√£o da regress√£o log√≠stica com outcome bin√°rio (sim ou n√£o) para mais vari√°veis preditoras. Nesse cen√°rio, o *log odds* passa a ser calculado por:

$$
\log\!\left(\frac{p(X)}{1 - p(X)}\right) = \beta_0 + \beta_1 X_1 + ... + \beta_p* X_p
$$

Onde X = ($X_1, ..., X_p$) s√£o os preditores. Da mesma forma que antes, o m√©todo de verossimilhan√ßa √© utilizado para estimar os par√¢metros $\beta_0, \beta_1, ...  ,\beta_p$.


### Regress√£o Log√≠stica Multinomial

At√© agora, trabalhamos com o caso de um outcome *Y* bin√°rio (sim ou n√£o, 0 ou 1). No entanto, em muitos casos estamos interessados em classificar mais de uma categoria/classe. Para tarefas em que o n√∫mero K de classes √© $>2$, utilizamos o *Multinomial Logit*, ou **Regress√£o Log√≠stica Multinomial**, que √© uma extens√£o da regress√£o log√≠stica para mais classes. Nessa extens√£o, uma das classes ser√° utilizada como base de compara√ß√£o para estimar os par√¢metros. $p(X)$ √© alterado da seguinte maneira:


$$
Pr(Y_i = K | X = x)
$$

Ou seja, a probabilidade de que a observa√ß√£o individual $Y_i$ seja de determinada categoria K, dado os valores das vari√°veis preditoras. Para estimar esse novo $p(X)$, estimamos

$$
\Pr\bigl(Y = k \mid X = x\bigr)
  = \frac{
        e^{\beta_{k0} + \beta_{k1}x_1 + \cdots + \beta_{kp}x_p}
      }{
        1 \;+\; \displaystyle\sum_{l=1}^{K-1}
              e^{\beta_{l0} + \beta_{l1}x_1 + \cdots + \beta_{lp}x_p}
      }.
$$

Que pode ser lida assim:

A **probabilidade** de um indiv√≠duo pertencer √† categoria *k* (entre K poss√≠veis) **dado** o vetor de preditores $x=(x_1,\dots,x_p)$ √© igual √† raz√£o entre   o **peso exponencial** atribu√≠do a essa categoria obtido somando o intercepto $\beta_{k0}$ ao efeito de cada preditor $x_j$ ponderado pelo seu coeficiente $\beta_{kj}$ e a soma desse mesmo peso **mais** os pesos de todas as demais categorias tomadas como compara√ß√£o.

Em outras palavras:

1. Para cada classe *k* calculamos um escore linear
$\beta_{k0} + \beta_{k1}x_1 + \dots + \beta_{kp}x_p$.
2. Transformamos esse escore em algo estritamente positivo aplicando a exponencial $e^{(\cdot)}$; isso garante que valores maiores de escore se convertam em pesos maiores.
3. A probabilidade final de estar na classe *k* √© esse peso dividido pela soma de:
    - 1 (peso da classe-de-refer√™ncia implicitamente tratada como $ \beta_{00}=0 $) **mais**
    - os pesos de todas as outras K‚àí1 classes explicitadas no denominador.

Assim, o modelo:

- Mant√©m todas as probabilidades no intervalo 0‚Äì1.
- Faz com que a soma das probabilidades sobre todas as K classes seja 1.
- Permite interpretar cada $\beta_{kj}$ como o efeito de $x_j$ na chance logar√≠tmica de estar na classe *k* em compara√ß√£o com a classe-refer√™ncia.

O *log odds* passa a ser


$$
\log\!\left(
      \frac{\Pr\!\bigl(Y = k \mid X = x\bigr)}
           {\Pr\!\bigl(Y = K \mid X = x\bigr)}
    \right)
  \;=\;
  \beta_{k0} + \beta_{k1}x_1 + \cdots + \beta_{kp}x_p.
$$

Onde o logaritmo da probabilidade de pertencer √† classe $k$ em compara√ß√£o com as outras classes √© igual √† uma equa√ß√£o linear com os preditores. A decis√£o da classe a ser utilizada como base de compara√ß√£o √©



```{admonition} üí¨ Com a palavra, os autores:
:class: quote
"irrelevante. Por exemplo, ao classificar atendimentos de emerg√™ncia em AVC, overdose de drogas e crise epil√©ptica, suponha que ajustemos dois modelos de regress√£o log√≠stica multinomial: um tomando AVC como refer√™ncia e outro tomando overdose de drogas como refer√™ncia. As estimativas dos coeficientes diferir√£o entre os dois modelos ajustados devido √† escolha distinta de refer√™ncia, mas os valores ajustados (previs√µes), os log-odds entre qualquer par de classes e os demais resultados importantes do modelo permanecer√£o iguais. Ainda assim, a interpreta√ß√£o dos coeficientes em um modelo de regress√£o log√≠stica multinomial deve ser feita com cuidado, pois ela depende da categoria de refer√™ncia."
({cite}`james2023introduction`., p. 145, tradu√ß√£o nossa)
```


## Modelos Generativos para Classifica√ß√£o

Os autores apresentam uma segunda classe de modelos comuns utilizados na classifica√ß√£o: os modelos generativos. Modelos generativos s√£o chamados assim porque buscam modelar explicitamente o processo de gera√ß√£o dos dados. Em vez de apenas aprender a rela√ß√£o direta entre as vari√°veis explicativas ($X$) e a vari√°vel resposta ($Y$), como fazem os modelos discriminativos, os modelos generativos aprendem a distribui√ß√£o conjunta $P(X, Y)$ ou, de forma equivalente, $P(X|Y)$ e $P(Y)$. Isso permite que eles n√£o s√≥ classifiquem exemplos, mas tamb√©m simulem ou gerem novos dados que seguem o mesmo padr√£o observado. Na pr√°tica, modelos generativos como Naive Bayes e LDA (Linear Discriminant Analysis) estimam como as caracter√≠sticas dos dados s√£o distribu√≠das dentro de cada classe e, a partir disso, calculam a probabilidade de um exemplo pertencer a cada categoria. Essa abordagem √© √∫til para entender melhor a estrutura dos dados e pode ser empregada em tarefas como classifica√ß√£o, detec√ß√£o de anomalias e gera√ß√£o de exemplos sint√©ticos.


Nesse tipo de modelos, podemos modelar a distribui√ß√£o dos $p$ preditores $X$ separadamente para cada classe em $Y$. com isso, usamos o **Teorema de Bayes** para obtermos as estimativas de $Pr (y=k | X= x)$.

### Por que n√£o Regress√£o Log√≠stica?

- Quando h√° separa√ß√£o substantiva entre as classes, as estimativas do *logit* podem ser inst√°veis;
- Se a distribui√ß√£o dos preditores $X$ for **aproximadamente** normal, os m√©todos generativos ser√£o mais precisos;
- Esses m√©todos se extendem naturalmente para um n√∫mero de classes $K >= 2$

### Teorema de Bayes

Suponha que queremos classificar uma observa√ß√£o entre uma em K classes, onde $K >= 2$. Sendo $\pi k$ a representa√ß√£o da probabilidade *a priori* de que uma observa√ß√£o escolhida aleatoriamente venha da $k_{√©sima}$ classe. E sendo $fk(x) = Pr(X|y = k)$ a fun√ß√£o de densidade de  X para uma observa√ß√£o da da $k_{√©sima}$ classe. Ent√£o, o teorema de Bayes estabelece que:

$$
\Pr\bigl(Y = k \mid X = x\bigr)
  = \frac{\pi_k\,f_k(x)}
         {\displaystyle\sum_{l=1}^{K} \pi_l\,f_l(x)}.
$$

A leitura "intuitiva" √© a seguinte: "Pegue o qu√£o comum cada classe √© na popula√ß√£o (o peso œÄ‚Çñ) e multiplique por qu√£o bem as caracter√≠sticas x se encaixam nessa classe (a verossimilhan√ßa f‚Çñ(x)). Depois compare esse peso com a soma dos pesos de todas as classes. A fra√ß√£o resultante √© exatamente a probabilidade de que a observa√ß√£o perten√ßa √† classe k."

Com isso temos a probabilidade posterior $pk(x)$ = $Pr(y= k | X= x)$, que √© a probabilidade de que uma observa√ß√£o pertence √† classe k, dado os valores dos preditores para aquela observa√ß√£o. Os modelos dessa parte do cap√≠tulo todos v√£o utilizar o teorema de Bayes como parte das estimativas das probabilidades $pk(x)$.

### *Linear Discriminant Analysis* (LDA)

O *Linear Discriminant Analysis* (LDA) √© um modelo generativo utilizado para tarefas de classifica√ß√£o, especialmente quando a vari√°vel resposta possui duas ou mais categorias. O LDA parte do princ√≠pio de que os dados de cada classe seguem uma distribui√ß√£o normal multivariada com m√©dias diferentes, mas compartilham a mesma matriz de covari√¢ncia. Ou seja, ele assume que, dentro de cada classe, as vari√°veis explicativas ($X$) t√™m distribui√ß√£o aproximadamente normal e que a dispers√£o dos dados √© semelhante entre as classes.

O funcionamento do LDA envolve dois passos principais: primeiro, ele estima a m√©dia e a vari√¢ncia das vari√°veis explicativas para cada classe, al√©m das probabilidades a priori de cada classe na popula√ß√£o. Em seguida, utiliza o Teorema de Bayes para calcular a probabilidade de uma nova observa√ß√£o pertencer a cada classe, combinando a verossimilhan√ßa dos dados com o peso de cada classe.

A fronteira de decis√£o do LDA entre as classes √© linear, pois o modelo constr√≥i uma combina√ß√£o linear das vari√°veis explicativas para separar as categorias. Isso significa que o LDA busca encontrar a linha (ou hiperplano, em dimens√µes maiores) que melhor discrimina entre as classes, maximizando a separa√ß√£o entre elas e minimizando a dispers√£o dentro de cada classe.

O LDA √© especialmente √∫til quando as suposi√ß√µes de normalidade e covari√¢ncia igual s√£o razo√°veis, e pode ser aplicado em problemas como reconhecimento de padr√µes, classifica√ß√£o de textos, diagn√≥stico m√©dico e an√°lise de cr√©dito. Al√©m de classificar novas observa√ß√µes, o LDA tamb√©m permite interpretar quais vari√°veis s√£o mais importantes para distinguir entre as classes, fornecendo insights sobre a estrutura dos dados.


### *Quadratic Discriminant Analysis* (QDA)

O *Quadratic Discriminant Analysis* (QDA) √© uma extens√£o do LDA que relaxa uma das principais suposi√ß√µes do modelo: enquanto o LDA assume que todas as classes compartilham a mesma matriz de covari√¢ncia, o QDA permite que cada classe tenha sua pr√≥pria matriz de covari√¢ncia. Isso significa que o QDA pode capturar situa√ß√µes em que a dispers√£o ou a forma das distribui√ß√µes das vari√°veis explicativas ($X$) √© diferente entre as classes.

No QDA, os dados de cada classe ainda s√£o modelados como provenientes de uma distribui√ß√£o normal multivariada, mas agora cada classe pode ter uma dispers√£o e correla√ß√£o entre vari√°veis pr√≥prias. Como resultado, a fronteira de decis√£o entre as classes deixa de ser linear e passa a ser quadr√°tica, permitindo separar classes que t√™m formatos ou distribui√ß√µes mais complexas.

O funcionamento do QDA envolve estimar, para cada classe, a m√©dia das vari√°veis explicativas, a matriz de covari√¢ncia espec√≠fica e a probabilidade a priori. Utilizando o Teorema de Bayes, o QDA calcula a probabilidade de uma nova observa√ß√£o pertencer a cada classe, levando em conta as diferen√ßas na dispers√£o dos dados.

O QDA √© especialmente √∫til quando as classes apresentam padr√µes de variabilidade distintos, como em problemas de classifica√ß√£o de imagens, reconhecimento de padr√µes ou situa√ß√µes em que a estrutura dos dados √© mais heterog√™nea. Por ser mais flex√≠vel que o LDA, o QDA pode se adaptar melhor a dados complexos, mas tamb√©m exige mais dados para estimar corretamente as matrizes de covari√¢ncia de cada classe.

### LDA ou QDA?


```{admonition} üí¨ Com a palavra, os autores:
:class: quote
"Por que importa se assumimos ou n√£o que as K classes compartilham uma matriz de covari√¢ncia comum? Em outras palavras, por que algu√©m preferiria LDA a QDA, ou vice-versa? A resposta est√° no trade-off vi√©s-vari√¢ncia. Quando h√° p preditores, estimar uma matriz de covari√¢ncia requer estimar p(p+1)/2 par√¢metros. O QDA estima uma matriz de covari√¢ncia separada para cada classe, somando Kp(p+1)/2 par√¢metros. Com 50 preditores, isso corresponde a m√∫ltiplos de 1 275, ou seja, muitos par√¢metros. Ao assumir que as K classes compartilham uma matriz de covari√¢ncia comum, o modelo LDA torna-se linear em x, o que implica Kp coeficientes lineares a estimar. Consequentemente, o LDA √© um classificador muito menos flex√≠vel que o QDA e, portanto, tem vari√¢ncia substancialmente menor. Isso pode levar a um desempenho de previs√£o melhor. Mas h√° um trade-off: se a suposi√ß√£o de que as K classes compartilham uma matriz de covari√¢ncia comum estiver muito errada, o LDA pode sofrer de alto vi√©s. De modo geral, o LDA tende a ser uma aposta melhor que o QDA quando h√° poucas observa√ß√µes de treino e, portanto, reduzir a vari√¢ncia √© crucial. Em contraste, o QDA √© recomendado se o conjunto de treino for muito grande, de modo que a vari√¢ncia do classificador n√£o seja uma grande preocupa√ß√£o, ou se a suposi√ß√£o de uma matriz de covari√¢ncia comum para as K classes for claramente insustent√°vel."
({cite}`james2023introduction`., p. 157, tradu√ß√£o nossa)
```

### *Naive Bayes*


O *Naive Bayes* √© outro modelo generativo amplamente utilizado em tarefas de classifica√ß√£o, especialmente em Processamento de Linguagem Natural. Sua principal caracter√≠stica √© a suposi√ß√£o de independ√™ncia condicional entre as vari√°veis explicativas ($X$) dado a classe ($Y$). Ou seja, o modelo assume que, dentro de cada classe, as vari√°veis s√£o estatisticamente independentes entre si ‚Äî uma simplifica√ß√£o que raramente √© verdadeira na pr√°tica, mas que torna o modelo extremamente eficiente e f√°cil de implementar.

O funcionamento do Naive Bayes envolve calcular, para cada classe, a probabilidade a priori ($P(Y)$) e a probabilidade de observar cada valor das vari√°veis explicativas dado a classe ($P(X_i|Y)$). Utilizando o Teorema de Bayes, o modelo combina essas probabilidades para estimar a probabilidade de uma nova observa√ß√£o pertencer a cada classe. Apesar da suposi√ß√£o "ing√™nua" de independ√™ncia, o Naive Bayes costuma apresentar bom desempenho em problemas de texto, como classifica√ß√£o de e-mails em spam ou n√£o spam, an√°lise de sentimentos e categoriza√ß√£o de documentos.

Al√©m de ser r√°pido e escal√°vel para grandes volumes de dados, o Naive Bayes √© robusto a dados faltantes e pode ser facilmente adaptado para diferentes tipos de vari√°veis (bin√°rias, categ√≥ricas ou cont√≠nuas). Em resumo, o Naive Bayes oferece uma solu√ß√£o pr√°tica e eficiente para problemas de classifica√ß√£o, especialmente quando a simplicidade e a velocidade s√£o prioridades.


## Conclus√£o

Neste cap√≠tulo, aprofundamos o entendimento sobre o problema de classifica√ß√£o em aprendizado supervisionado, destacando as limita√ß√µes da regress√£o linear para vari√°veis categ√≥ricas e a import√¢ncia de utilizar m√©todos apropriados para tarefas de classifica√ß√£o. Exploramos a regress√£o log√≠stica, suas extens√µes para m√∫ltiplos preditores e m√∫ltiplas classes, e discutimos o papel do logit como liga√ß√£o entre vari√°veis explicativas e probabilidades. Apresentamos tamb√©m os modelos generativos, como LDA, QDA e Naive Bayes, que modelam explicitamente o processo de gera√ß√£o dos dados e utilizam o Teorema de Bayes para estimar probabilidades de pertencimento √†s classes. Discutimos os pressupostos, vantagens e limita√ß√µes de cada abordagem, bem como o trade-off entre vi√©s e vari√¢ncia na escolha do modelo. Por fim, refor√ßamos a import√¢ncia de compreender as caracter√≠sticas dos dados e dos m√©todos para realizar classifica√ß√µes precisas, interpret√°veis e adequadas ao contexto de cada problema.

## Notas

[^1]: **Classificadores** s√£o modelos de aprendizado de m√°quina supervisionado projetados para atribuir exemplos a categorias ou classes distintas com base em suas caracter√≠sticas. Eles s√£o utilizados quando a vari√°vel resposta √© categ√≥rica, como na identifica√ß√£o de sentimentos em textos, classifica√ß√£o de imagens ou detec√ß√£o de spam em e-mails.