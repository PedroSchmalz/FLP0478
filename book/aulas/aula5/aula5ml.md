# Aprendizado Supervisionado II

Na √∫ltima aula, vimos que o Aprendizado de m√°quina √© um campo dentro da Intelig√™ncia artificial que busca, com base em experi√™ncias pr√©vias (i.e. dados de treinamento), fazer classifica√ß√µes ou previs√µes para nossa vari√°vel de interesse (*target*). Para isso, os m√©todos de aprendizado estat√≠stico precisam de uma fun√ß√£o erro, que busca reduzir a dist√¢ncia entre os valores previstos e os valores reais dos dados de treinamento. Vimos tamb√©m os passos principais para a cria√ß√£o de um banco de dados de treinamento (Codebook, anota√ß√£o, concord√¢ncia entre anotadores), e o *pipeline* b√°sico de uma aplica√ß√£o de classifica√ß√£o. Destacamos m√©tricas essenciais como acur√°cia, precis√£o, recall e F1-score para avaliar o desempenho dos classificadores. Por fim, refor√ßamos a import√¢ncia de testar o modelo em dados novos para garantir sua capacidade de generaliza√ß√£o e utilidade pr√°tica. Na aula de hoje, retomaremos algumas discuss√µes da aula anterior, e discutiremos a diferen√ßa entre infer√™ncia e predi√ß√£o, m√©todos param√©tricos e n√£o-param√©tricos, e os trade-offs cl√°ssicos de aprendizado de m√°quina entre Flexibilidade x Interpretabilidade, e vi√©s x vari√¢ncia.


Como dito, o objetivo de uma tarefa de aprendizado de m√°quina √© usar um conjunto de dados para fazer previs√µes e classifica√ß√µes para outros dados n√£o observados durante o treinamento. Esse conjunto de dados √© conhecido como o **banco de treinamento** (ou C√≥rpus anotado, em PLN), e √© composto de dois tipos de vari√°veis principais: A vari√°vel ***Target*** (alvo), representada muitas vezes por $Y$, e tamb√©m conhecida por vari√°vel resposta, vari√°vel dependente, ou vari√°vel explicada. O segundo tipo de vari√°vel √© o que √© chamado, no *ML*, de ***Features***, representadas por $\mathbf{X}$, que s√£o vetores de vari√°veis preditoras, ou independentes/explicativas, ou vari√°veis *input*. No contexto de Processamento da L√≠ngua Natural, nosso principal $X$ √© o texto em cada documento, e o principal $Y$ (em classifica√ß√£o) s√£o as categorias de interesse, seja sentimento, posicionamento, relev√¢ncia, t√≥picos, etc. Na literatura de Aprendizado Estat√≠stico e de Aprendizado de m√°quina, $X$ e $Y$ podem ser referidos de todas as formas mencionadas acima, mas significam a mesma coisa. 

Com esse banco de dados de treinamento, contendo $\mathbf{X}$ e $Y$, o principal objetivo √© de modelar a rela√ß√£o entre eles, tal que tenhamos

$$
 Y = f(x) + \epsilon
$$

Em que $Y$ √© nosso *target* (e.g. Sentimento, posicionamento) e $\mathbf{x}$ √© o vetor de nossas vari√°veis explicativas (o Texto em representa√ß√£o num√©rica). $f(x)$ seria, portanto, uma fun√ß√£o geral que representa a rela√ß√£o entre nossas *features* e o *target*.

## Por que estimar $f(x)$?


Existem dois contextos em que o pesquisador est√° interessado em estimar $f(x)$: Infer√™ncia e Predi√ß√£o. Grosso modo, as pesquisas em **infer√™ncia** procuram entender o impacto de cada vari√°vel explicativa ($X_1, X_2, ..., X_p$) em $Y$, e como essa rela√ß√£o se altera com a inclus√£o de novas vari√°veis, intera√ß√µes, polin√¥mios, etc. Por exemplo, uma pesquisa pode estar preocupada em entender como a religi√£o de um indiv√≠duo pode impactar em seu apoio ao bolsonarismo. Um poss√≠vel resultado dessa pesquisa poderia ser de que o indiv√≠duo ser evang√©lico tem um efeito positivo constante no apoio ao bolsonarismo, em compara√ß√£o com outras religi√µes/denomina√ß√µes. 

No contexto da **predi√ß√£o**, o foco √© em utilizar os dados de treinamento rotulados (e, com isso, as vari√°veis $X_1, X_2, ..., X_p $) para prever os valores de $Y$, sejam estes valores cont√≠nuos ou categ√≥ricos. Um exemplo cl√°ssico de classifica√ß√£o neste contexto √© o de classifica√ß√£o de e-mails em *Spam* ou n√£o *Spam*. Nessa tarefa, utiliza-se o texto do email em alguma representa√ß√£o num√©rica (*Bag-of-words*, *embeddings*, etc.) para a classifica√ß√£o bin√°ria de *Spam* ou n√£o. 

### Predi√ß√£o

No contexto de predi√ß√£o, estimamos os seguintes valores:

$$
\hat{y} = \hat{f}(\mathbf{x})
$$


Onde $\hat{f}$ √© a estimativa de $f$ e $\hat{y}$ √© a estimativa de $y$. Aqui, $\hat{f}$ √© tratado como uma "caixa preta", no sentido de que a preocupa√ß√£o n√£o √© com sua forma, nem com sua especifica√ß√£o, mas se ele fornece boas previs√µes de $y$. No exemplo do e-mail, n√£o importa quais palavras s√£o melhores preditoras de se um e-mail √© ou n√£o *spam*, mas sim que o modelo consiga classificar corretamente essa categoria, na maior parte dos casos. A precis√£o da fun√ß√£o $\hat{f}$ √© determinada por dois tipos de erro: um redut√≠vel e outro irredut√≠vel. Mesmo que tenhamos um √≥timo modelo e especifica√ß√£o, ainda existir√° uma parcela de erro devido √† fatores estoc√°sticos (i.e. aleat√≥rios).


````{margin}
```{note}
Um problema comum que pode existir em aplica√ß√µes de aprendizado de m√°quina √© o *data leakage*. *Data leakage* √© um problema que ocorre quando informa√ß√µes do conjunto de teste ou de valida√ß√£o acabam sendo utilizadas, direta ou indiretamente, durante o treinamento do modelo. Isso faz com que o modelo tenha acesso a dados que n√£o deveria conhecer, levando a resultados artificialmente altos nas m√©tricas de avalia√ß√£o e prejudicando sua capacidade de generaliza√ß√£o para dados realmente novos. Portanto, sabendo que existe um erro irredut√≠vel nas aplica√ß√µes de predi√ß√£o, resultados **bons demais** na valida√ß√£o e teste (i.e. resultados muito pr√≥ximos da perfei√ß√£o) podem indicar que o pesquisador est√° com vazamento de dados.
```
````

$$
 E(y-\hat{y}) = E[f(x)+ \epsilon - \hat{f}(x)]¬≤ \\
 = [f(x)-\hat{f}(x)]¬≤ + Var(\epsilon)
$$

Onde

$$
\underbrace{[f(x)-\hat{f}(x)]^2}_{\text{Erro redut√≠vel: diferen√ßa entre a fun√ß√£o verdadeira e a estimada}} \\
$$

$f(x)$ seria a verdadeira rela√ß√£o de vari√°veis que melhor explicam e prevem $y$ (ou o verdadeiro *Data Generating Process*) e $\hat{f}(x)$ √© a fun√ß√£o que o pesquisador estabeleceu com as vari√°veis existentes no banco de dados. Sempre √© poss√≠vel, com base na rotula√ß√£o de treinamento, reduzir a diferen√ßa entre o que encontramos nos dados e o que melhor aproxima $y$. No entanto, o outro componente da equa√ß√£o √©


$$
+ \underbrace{Var(\epsilon)}_{\text{Erro irredut√≠vel: variabilidade aleat√≥ria dos dados}}
$$

Esse erro √© irredut√≠vel e estoc√°stico, e sempre estar√° presente em qualquer aplica√ß√£o, seja ela inferencial ou de previs√£o. Esse erro faz com que, independente da nossa especifica√ß√£o de $\hat{f}(x)$, $E(y-\hat{y})$ nunca ser√° igual a zero. Aqui est√£o dois exemplos de tarefas de predi√ß√£o:

**Predi√ß√£o de valores cont√≠nuos (Regress√£o):**  
Um pesquisador deseja prever o pre√ßo de casas em uma cidade com base em vari√°veis como n√∫mero de quartos, √°rea constru√≠da, localiza√ß√£o e idade do im√≥vel. O banco de treinamento cont√©m registros dessas caracter√≠sticas ($\mathbf{X}$) e o pre√ßo real de cada casa ($Y$). O objetivo √© estimar uma fun√ß√£o $\hat{f}(\mathbf{x})$ que, ao receber as caracter√≠sticas de uma nova casa, forne√ßa uma previs√£o do seu pre√ßo ($\hat{y}$), um valor cont√≠nuo. 

**Predi√ß√£o em PLN com classifica√ß√£o:**  
Em Processamento de Linguagem Natural, uma tarefa comum √© classificar textos em categorias espec√≠ficas. Por exemplo, considere um sistema de an√°lise de sentimentos aplicado a avalia√ß√µes de produtos online. O banco de treinamento √© composto por textos de avalia√ß√µes ($\mathbf{X}$) e o r√≥tulo correspondente ($Y$), indicando se a avalia√ß√£o √© positiva, negativa ou neutra. O modelo aprende padr√µes lingu√≠sticos e de frequ√™ncia de palavras para estimar $\hat{f}(\mathbf{x})$ e, ao receber uma nova avalia√ß√£o, prev√™ o sentimento expresso pelo usu√°rio ($\hat{y}$), realizando uma classifica√ß√£o multiclasse. Esse tipo de tarefa √© essencial para empresas que desejam monitorar a satisfa√ß√£o dos clientes, identificar problemas recorrentes em produtos ou servi√ßos, e tomar decis√µes estrat√©gicas baseadas no feedback dos usu√°rios.

Outro exemplo relevante de classifica√ß√£o em PLN √© a detec√ß√£o autom√°tica de not√≠cias falsas (*fake news*). Nesse caso, o banco de treinamento cont√©m textos de not√≠cias ($\mathbf{X}$) e o r√≥tulo ($Y$) indicando se a not√≠cia √© verdadeira ou falsa. O modelo pode ser treinado para identificar padr√µes de linguagem, fontes e estrutura textual que diferenciam not√≠cias confi√°veis de not√≠cias enganosas, auxiliando plataformas digitais e leitores na filtragem de informa√ß√µes e combate √† desinforma√ß√£o.

### Infer√™ncia

No contexto da infer√™ncia, tamb√©m h√° a preocupa√ß√£o de estimar $f$. No entanto, o foco est√° em entender a associa√ß√£o entre $y$ e $X = \{X_1, X_2, ..., X_p\}$. Diferente da predi√ß√£o, onde o objetivo principal √© prever valores futuros ou desconhecidos, a infer√™ncia busca interpretar e explicar como as vari√°veis explicativas influenciam o resultado. Algumas perguntas comuns nesse tipo de estudo incluem:

- Quais vari√°veis explicativas est√£o associadas com $y$?
- Qual a rela√ß√£o de cada $X_i$ com $y$?
- Essa rela√ß√£o √© linear ou mais complexa?
- Qual o efeito de uma mudan√ßa em $X_i$ sobre $y$?

**Exemplo 1: Infer√™ncia em regress√£o linear**  
Um pesquisador deseja entender como fatores socioecon√¥micos, como renda, escolaridade e idade, influenciam o n√≠vel aprova√ß√£o de pol√≠ticos (e.g. Governador do estado, Presidente, etc.). Utilizando um modelo de regress√£o linear, ele pode estimar o efeito de cada vari√°vel explicativa sobre a aprova√ß√£o ($Y$), interpretando os coeficientes para identificar quais fatores t√™m maior impacto e se essas rela√ß√µes s√£o positivas ou negativas.

**Exemplo 2: Infer√™ncia em PLN**  
Em Processamento de Linguagem Natural, um estudo pode investigar quais caracter√≠sticas textuais est√£o associadas √† viraliza√ß√£o de postagens em redes sociais. O pesquisador pode analisar vari√°veis como o uso de emojis, hashtags, comprimento do texto e presen√ßa de palavras-chave, buscando entender como cada uma dessas vari√°veis ($X_i$) contribui para o n√∫mero de compartilhamentos ou curtidas ($Y$). O objetivo n√£o √© apenas prever se uma postagem ser√° viral, mas explicar quais elementos do texto aumentam ou diminuem essa probabilidade.

**Exemplo 3: Infer√™ncia em classifica√ß√£o**  
Outro exemplo √© um estudo sobre fatores que influenciam a classifica√ß√£o de not√≠cias como verdadeiras ou falsas. Ao inv√©s de apenas construir um modelo para detectar fake news, o pesquisador pode examinar quais padr√µes lingu√≠sticos, fontes ou estruturas textuais est√£o estatisticamente associados √† veracidade das not√≠cias, permitindo uma compreens√£o mais profunda dos mecanismos de desinforma√ß√£o.


## Como estimar $f$?

Estabelecemos que, em infer√™ncia ou predi√ß√£o, o objetivo principal √© estimar a fun√ß√£o $\hat{f}$ tal que $y \approx \hat{f}(x)$ para cada par de observa√ß√µes ($x_i, y_i$). Os m√©todos/modelos que podem fazer essa estima√ß√£o est√£o divididos em dois grupos: **Param√©tricos** e **N√£o Param√©tricos**.


### M√©todos Param√©tricos

M√©todos param√©tricos geralmente operam em dois passos:

1. Definir ou especificar a forma funcional de $f$. Para isso, precisa escolher as vari√°veis explicativas de interesse, se a rela√ß√£o com $Y$ ser√° linear ou n√£o, se existem intera√ß√µes entre as vari√°veis independentes, etc. Vamos olhar para uma regress√£o linear univariada:

$$
Y = \beta_0 + \beta_1*X_1
$$

Talvez voc√™ j√° tenha visto algo muito similar quando estudou a equa√ß√£o reduzida da reta:

$$
Y = mX + b
$$

$b$, ou o coeficiente linear, √© o ponto onde a reta intercepta o eixo y. Na regress√£o linear univariada, estimamos o $\beta_0$, que tamb√©m √© o coeficiente linear. $m$ √© o coeficiente angular, que na regress√£o univariada √© representado por $\beta_1$, e mostra o quanto $y$ varia com o aumento de $x$. Essa regress√£o pode ser generalizada para mais vari√°veis (ainda sendo uma regress√£o linear):

$$
Y = \beta_0 + \beta_1*X_1 + \beta_2*X_2 + ... + \beta_p * X_p
$$


Onde $p$ √© o n√∫mero de vari√°veis a serem inclu√≠das. No exemplo de James et al. ({cite}`james2023introduction`.), temos um modelo sobre a renda em fun√ß√£o de anos de estudo e *seniority* (quantos anos o indiv√≠duo trabalha na empresa). 

2. Com as vari√°veis e forma de $f$ definidas, precisamos escolher um modo de fazer o *fit* do modelo √†s observa√ß√µes. Isto √©, precisamos estimar os par√¢metros $\beta_0, \beta_1, ..., \beta_p$. O m√©todo mais comum em regress√£o linear para estimar esses par√¢metros √© o *OLS*, *Ordinary Least Squares*



```{figure} ../aula5/images/fig2.4.png
---
width: 100%
name: income
align: center
---
Modelo Linear da Rela√ß√£o entre Renda do indiv√≠duo, anos de educa√ß√£o e *seniority*. Fonte: James et al. ({cite}`james2023introduction`., p. 21)
```


A {numref}`Figura {number} <income>` mostra como ficaria um modelo OLS na representa√ß√£o 3D da rela√ß√£o entre Renda, Anos de educa√ß√£o, e senioridade. Apesar de parecer um pouco estranho por estar em tr√™s dimens√µes, essa rela√ß√£o √© linear. Analisando o quadrante que mostra a evolu√ß√£o entre renda e anos de educa√ß√£o, parece que √° uma rela√ß√£o linear positiva: quanto mais anos de educa√ß√£o, maior a renda. O mesmo parece acontecer com *seniority*. Esse m√©todo √© param√©trico justamente por que o pesquisador define a forma funcional e como as vari√°veis $X_i$ se relacionam com a vari√°vel explicativa $Y$. Ap√≥s definir a forma, o pesquisador deve escolher um m√©todo para estimar os **Par√¢metros** $\beta_0, \beta_1, ..., \beta_p$. 

Entre os m√©todos param√©tricos mais conhecidos est√£o a regress√£o linear, a regress√£o log√≠stica, o modelo de Poisson e o modelo de sobreviv√™ncia de Cox. Esses m√©todos assumem uma forma funcional espec√≠fica para a rela√ß√£o entre as vari√°veis explicativas e o resultado, permitindo a interpreta√ß√£o direta dos par√¢metros estimados e facilitando a an√°lise dos efeitos individuais.


### M√©todos N√£o-Param√©tricos

Em contraposi√ß√£o aos m√©todos param√©tricos, os m√©todos **n√£o-param√©tricos** n√£o assumem uma forma funcional de $f$, procurando estim√°-lo de forma a chegar bem perto das observa√ß√µes individuais, sem ser muito r√≠gido nem flex√≠vel demais. No exemplo da renda do indiv√≠duo, ainda usamos as vari√°veis de anos de estudo e *seniority*, mas n√£o definimos se essa rela√ß√£o √© linear, se h√° intera√ß√£o entre as vari√°veis explicativas, etc.


```{admonition} üí¨ Com a palavra, os autores:
:class: quote
"Essas abordagens podem apresentar uma grande vantagem em rela√ß√£o √†s param√©tricas: ao evitar a suposi√ß√£o de uma forma funcional espec√≠fica para f, t√™m o potencial de ajustar com precis√£o uma gama bem mais ampla de formatos poss√≠veis para f. Toda abordagem param√©trica traz consigo a possibilidade de que a forma funcional usada para estimar f seja muito diferente da verdadeira f, caso em que o modelo resultante n√£o descrever√° bem os dados. Em contraste, as abordagens n√£o param√©tricas eliminam completamente esse risco, j√° que praticamente n√£o se assume nada sobre a forma de f. Entretanto, as abordagens n√£o param√©tricas sofrem de uma grande desvantagem: como n√£o reduzem o problema de estimar f a um pequeno conjunto de par√¢metros, √© necess√°rio um n√∫mero muito maior de observa√ß√µes (bem acima do normalmente exigido por uma abordagem param√©trica) para se obter uma estimativa precisa de f."
({cite}`james2023introduction`., p. 22, tradu√ß√£o nossa)
```



```{figure} ../aula5/images/fig2.6.png
---
width: 100%
name: incomenonpar
align: center
---
Modelo N√£o Param√©trico da Rela√ß√£o entre Renda do indiv√≠duo, anos de educa√ß√£o e *seniority*. Fonte: James et al. ({cite}`james2023introduction`., p. 23)
```
















