# Sobreajuste, Reamostragem e Valida√ß√£o dos Resultados

Na √∫ltima aula, vimos que a transi√ß√£o da classifica√ß√£o tradicional com vari√°veis num√©ricas para a classifica√ß√£o de textos exige primeiro **converter a linguagem em n√∫meros**, e foi a√≠ que aprofundamos os modelos de linguagem *n-gram*. Discutimos como unigramas, bigramas e trigramas capturam diferentes n√≠veis de contexto e por que a suposi√ß√£o de Markov e a Regra da Cadeia permitem estimar probabilidades de sequ√™ncias mesmo em corpus limitados. Essa base probabil√≠stica ficou clara quando mostramos que **classificadores como a regress√£o log√≠stica**, apresentados esta semana, continuam seguindo o mesmo princ√≠pio: atribuir pesos √†s features‚Äîneste caso, contagens ou frequ√™ncias de *n-grams*‚Äîpara modelar $Pr(Y\! =\! 1\mid X)$ por meio da fun√ß√£o sigmoide, ou do softmax quando temos mais de duas classes. Finalmente, amarramos essas ideias ao processo de treinamento: definimos a perda em cross-entropy, vimos como o gradiente descende essa fun√ß√£o e por que hiperpar√¢metros como a learning rate influenciam a converg√™ncia do modelo. Em suma, o encontro uniu teoria de modelos de linguagem e pr√°tica de classifica√ß√£o supervisionada, mostrando que **entender *n-grams* √© o primeiro passo para aplicar algoritmos como regress√£o log√≠stica a tarefas de sentimento, spam ou t√≥picos**. 

Na aula de hoje, iremos discutir um problema que n√£o √© √∫nico ao texto em Aprendizado de M√°quina: o Sobreajuste (ou ***overfitting***), e como identific√°-lo e evit√°-lo. O problema decorre do fato de que muitos m√©todos estat√≠sticos/de Aprendizado de M√°quina s√£o facilmente adapt√°veis e capazes de modelar rela√ß√µes complexa (Mesmo antes da difus√£o do *Deep Learning*!). No entanto, podem acabar enfatizando demais caracter√≠sticas dos dados de treinamento que n√£o est√£o no teste (ou no mundo), o que vai impactar sua capacidade de generaliza√ß√£o para outros casos[^1]. Por isso, precisamos garantir que nossos modelos s√£o confi√°veis e podem ser usados para previs√£o. Sem essa confian√ßa, os modelos s√£o in√∫teis.


## Sobreajuste (*Overfitting*)

Existem t√©cnicas de aprendizado estat√≠stico que s√£o capazes de "aprender" t√£o bem as caracter√≠sticas de um banco de treinamento que podem fazer previs√µes corretas para todas as observa√ß√µes. Esse tipo de modelo √© conhecido como um modelo sobreajustado, ou *over-fit*, e provavelmente n√£o vai se sair muito bem em novas amostras. Vamos imaginar uma tarefa de classifica√ß√£o bem simples em que h√° somente dois preditores: A e B, e um modelo deve classific√°-la entre a classe azul e a classe vermelha (simula√ß√£o).

```{figure} ../aula8/images/kkfig.4.2.png
---
width: 100%
name: figkkclass
align: center
---
Exemplo de um banco de treinamento com duas classes e preditores. Os pain√©is mostram dois modelos de classifica√ß√£o e seus limites de classifica√ß√£o. Fonte Kuhn and Kjell (p.63, {cite}`kuhn2018applied`.)
```

Como mostra A {numref}`Figura {number} <figkkclass>`, o modelo 1 seria um modelo sobreajustado, pois tenta definir os limites para a classifica√ß√£o muito pr√≥ximos tamb√©m aos casos at√≠picos. Isto √©, os casos azuis que est√£o para valores dos preditores maiores do que 0.5 (ambos preditores). Com esse sobreajuste, com certeza o modelo apresentaria √≥timos resultados no banco de treinamento, mas performaria muito mal em novas observa√ß√µes, justamente por tentar se aproximar muito de como as observa√ß√µes se comportaram no treinamento. O segundo modelo, apesar de admitir mais erro durante o treinamento, provavelmente apresentaria melhores resultados em observa√ß√µes n√£o vistas e, portanto, melhor capacidade de generaliza√ß√£o. Esse √© o ponto principal do problema: Queremos conseguir identificar quando nosso modelo est√° sobreajustado, e qual modelo ter√° melhores resultados em novas observa√ß√µes. N√≥s vimos isso acontecer anteriormente na quinta aula, quando avaliamos o resultado de treinamento e teste de alguns modelos com base na sua flexibilidade, na {numref}`Figura {number} <flexteste>`:

```{figure} ../aula5/images/fig2.9.png
---
width: 100%
name: flexteste
align: center
---
√Ä esquerda: dados simulados a partir de f, mostrados em preto. Tr√™s estimativas de f s√£o exibidas: a linha de regress√£o linear (curva laranja) e dois ajustes por splines de suaviza√ß√£o (curvas azul e verde).

√Ä direita: Erro Quadr√°tico M√©dio de treinamento (curva cinza), EQM de teste (curva vermelha) e EQM m√≠nimo poss√≠vel de teste entre todos os m√©todos (linha tracejada). Os quadrados representam os EQMs de treinamento e de teste para os tr√™s ajustes mostrados no painel da esquerda. Fonte: James et al. ({cite}`james2023introduction`., p. 29).
```

Nesse caso, temos um modelo sobreajustado, que √© representado na linha verde: Ele segue bem de perto a varia√ß√£o estoc√°stica de cada observa√ß√£o, e consegue √≥timos resultados no treinamento (quadrado verde, linha cinza). No entanto, vemos que seu resultado √© ruim para o banco de teste (linha vermelha), s√≥ n√£o sendo pior do que a regress√£o linear, que nesse caso foi um modelo subajustado (*under-fit*). Nas nossas aplica√ß√µes, sempre almejamos o modelo azul (corretamente ajustado), e, apesar de n√£o sabermos o verdadeiro erro m√≠nimo poss√≠vel, podemos comparar diversos modelos e suas estimativas com m√©todos de reamostragem, escolhendo o melhor modelo dentre os testados. 


Vamos tentar imaginar como isso ocorreria com texto em um exemplo simples. Considere um mini‚Äêconjunto de tweets sobre um filme. Temos o seguinte banco de Treino fict√≠tico para uma classifica√ß√£o de sentimento (6 frases, r√≥tulos entre par√™nteses):

1. ‚ÄúAmei muito este filme!‚Äù (+)
2. ‚ÄúFilme incr√≠vel, recomendo!‚Äù (+)
3. ‚ÄúObra-prima total.‚Äù (+)
4. ‚ÄúOdiei esse filme demais.‚Äù (‚àí)
5. ‚ÄúP√©ssimo enredo, detestei.‚Äù (‚àí)
6. ‚ÄúTerr√≠vel do come√ßo ao fim.‚Äù (‚àí)

Para transformar texto em n√∫meros aplicamos um modelo *bag-of-words* de **trigramas**: cada sequ√™ncia de tr√™s palavras vira uma feature, gerando dezenas de colunas muito espec√≠ficas (‚Äúamei muito este‚Äù, ‚Äúesse filme demais‚Äù etc.). Treinamos uma **regress√£o log√≠stica** sem regulariza√ß√£o; como h√° exatamente um trigrama exclusivo para cada frase, o algoritmo pode facilmente encontrar pesos que se encaixam perfeitamente e atingir 100% de acur√°cia no conjunto de treino. No entanto, imaginemos o seguinte banco de teste:

Teste (2 frases nunca vistas):

7. ‚ÄúAdorei esse filme.‚Äù (+)
8. ‚ÄúHorr√≠vel, n√£o gostei.‚Äù (‚àí)

Nenhum trigama do teste aparece no treino, logo o modelo poder√° atribuir probabilidades aleat√≥rias e classificar ambas como negativas ou positivas, resultando em apenas 50% de acerto (ou errar ambas). O sistema **memoriza ru√≠do em vez de aprender padr√µes gerais**, o que √© uma evid√™ncia de sobreajuste. Poder√≠amos trocar para unigramas ou aplicar regulariza√ß√£o para reduzir a complexidade e recuperar a capacidade de generaliza√ß√£o. Mas precisamos saber identificar quando estamos com sobreajuste.



```{admonition} üí¨ Com a palavra, os autores:
:class: quote
"Ao fazer o processamento computacional de textos escritos, a defini√ß√£o de que tipo de unidade de processamento se quer buscar/estudar parece estar atrelada √†s necessidades da tarefa ou trabalho pretendidos. Geralmente, considera-se que uma palavra √©, simplesmente, uma unidade grafol√≥gica delimitada, nas l√≠nguas europeias, entre espa√ßos em branco na representa√ß√£o gr√°fica, ou entre um espa√ßo em branco e um sinal de pontua√ß√£o. Essa √© uma defini√ß√£o bastante concreta, e bastante pr√°tica. No entanto, ao pensarmos em nossos modelos computacionais e suas aplica√ß√µes no mundo, √© importante nos aprofundarmos um pouco mais na conceitua√ß√£o do que √© uma palavra e nas possibilidades de processamento e implica√ß√µes das decis√µes tomadas no pr√©-processamento dos corpora."
({cite}`caseli_nunes_pln_2024`., p. 68, tradu√ß√£o nossa)
```

## Reamostragem e Valida√ß√£o Cruzada

```{video} https://www.youtube.com/embed/fSytzGwwBVw?si=1si6a5JK_COrLkHa
```

---

Justamente para que sejamos capazes de identificar quando estamos na situa√ß√£o de sobreajuste que surgiram os m√©todos de Reamostragem. **M√©todos de Reamostragem**, ou *Resampling*, s√£o ferramentas indispens√°veis na estat√≠stica e no aprendizado de m√°quina, e consistem em sortear amostras repetidas de um determinado conjunto de dados de treinamento, reajustando o modelo em cada nova amostra e obtendo informa√ß√µes adicionais sobre seu ajuste e incerteza. 

M√©todos de reamostragem podem ser utilizados para estimar o erro de um modelo ou para selecionar o n√≠vel de flexibilidade (como vimos na {numref}`Figura {number} <flexteste>`). O processo de avaliar a performance de um modelo √© conhecido como **Valida√ß√£o do Modelo**, e o processo de escolher hiperpar√¢metros e/ou flexibilidade do modelo √© conhecido como **Sele√ß√£o do modelo** (ou *hyperparameter tuning*).

Durante o curso, discutimos muito o valor de erro do modelo no banco de teste. o Erro de Teste √© a m√©dia dos erros que resultam das previs√µes do modelo em uma nova observa√ß√£o, que n√£o foi vista durante o treinamento. No entanto, a distin√ß√£o entre banco de treino e teste pode ser um pouco ilus√≥ria: Na verdade, n√£o temos um banco anotado separado s√≥ para teste, mas um banco de treinamento que foi repartido para treinamento e teste. Na aus√™ncia do banco de teste ideal, usamos m√©todos de valida√ß√£o para verificar a capacidade de generaliza√ß√£o de um modelo.

## Abordagem do Conjunto de Valida√ß√£o/Teste


```{video} https://www.youtube.com/embed/ngrOYWgJjb4?si=V1M2QpZVbXRwqcyl
```


---

Ao longo do curso, j√° usamos um m√©todo de valida√ß√£o. Dividimos um banco de treinamento em duas partes: treino e teste. O banco de teste tamb√©m pode ser chamado de banco de valida√ß√£o. Com esse m√©todo, treinamos o modelo no banco de treinamento e avaliamos sua performance no banco de teste. A {numref}`Figura {number} <treinoteste>` ilustra a divis√£o neste m√©todo.


```{figure} ../aula8/images/islfig5.1.png
---
width: 100%
name: treinoteste
align: center
---
Divis√£o entre o banco de treino (azul) e teste/valida√ß√£o (bege). Fonte: James et al. ({cite}`james2023introduction`., p. 203)
```

Uma das principais desvantagens desse m√©todo sozinho √© que, ao repetirmos o processo de separa√ß√£o entre treino e teste, obteremos resultados bem diferentes. A figura {numref}`Figura {number} <testevar>` mostra a vari√¢ncia das estimativas de erro obtida com diferentes divis√µes entre treino e teste. Fica claro que a aleatoriedade contida nessa divis√£o pode afetar bastante nossa estimativa: n√£o temos como saber quando estaremos na linha amarela (menor MSE) ou na linha laranja (maior MSE). Portanto, precisaremos de outros m√©todos para termos mais confian√ßa em nossos modelos.


```{figure} ../aula8/images/islfig.5.2.png
---
width: 100%
name: testevar
align: center
---
Uma √∫nica divis√£o entre treino e teste (Esquerda) e m√∫ltiplos resultados em v√°rias divis√µes (Direita). Fonte: James et al. ({cite}`james2023introduction`., p. 204)
```

Em resumo, o m√©todo de valida√ß√£o s√≥ bom com o banco de teste tem duas desvantagens principais: 1) A estimativa de erro ser√° √∫nica, e pode variar bastante dependendo de quais observa√ß√µes entraram no banco de teste. 2) O modelo treinar√° com menos observa√ß√µes (80 ou 90%), gerando resultados que podem supersestimar o erro de teste.


## Abordagem *Leave-one-out* (LOOCV)









## Notas

[^1]: A capacidade de generaliza√ß√£o √© a habilidade de um modelo de aprendizado de m√°quina manter alta precis√£o quando recebe dados que nunca fizeram parte do treinamento, porque aprendeu os padr√µes subjacentes em vez de memorizar casos espec√≠ficos. Quando o modelo √© complexo demais para a quantidade ou a qualidade dos dados, ele tende ao *overfitting*. Ou seja, acerta o treinamento, mas falha nos exemplos novos; E se for simples demais, ocorre *underfitting*, pois n√£o captura nem mesmo os padr√µes b√°sicos.