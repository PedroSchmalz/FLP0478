# Leituras

## Aula 14 - LLMs e outras ferramentas
___

**Leituras Obrigatórias:**  
- Jurafsky, D. and Martin, J. H. (2024). {cite}`jurafsky2024speech`. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models. 3rd edition. Capitulo 7: "Large Language Models", Capítulo 8 "Transformers" e Capítulo 10 "Post-training: Instruction Tuning, Alignment, and Test-Time Compute";


**Objetivos da aula:**  
- Introduzir os alunos ao *Large Language Models*
- O que é pretraining nas LLMs;
- Few-shot e Zero-shot;
- Como pensar as LLMs no contexto de classificação supervisionada.


**Leituras Complementares:**

- RASCHKA, Sebastian (2024). {cite}`raschka2024build`. Build a Large Language Model From Scratch. Shelter Island, NY: Manning Publications, 2024.
- ALAMMAR, Jay; GROOTENDORST, Maarten (2024). {cite}`alammar2024handson`. Hands-On Large Language Models: Language Understanding and Generation. Sebastopol, CA: O'Reilly Media, Inc., 2024.
- XIAO, Tong; ZHU, Jingbo (2025). {cite}`xiao2025foundations`. Foundations of Large Language Models. NLP Lab, Northeastern University; NiuTrans Research, 2025.







