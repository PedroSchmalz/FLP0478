# Classifica√ß√£o com Texto

Discutimos ao longo do curso que a tarefa de classifica√ß√£o envolve pegar preditores $X$ (ou *features*) e utiliz√°-los para tentar prever √† que categoria $Y$, nosso *target* pertence. Para a classifica√ß√£o com texto, a principal mudan√ßa √© a de que n√£o utilizaremos mais dados num√©ricos (Saldo do cart√£o, vari√°veis de sa√∫de), e sim **Texto**, pr√©-processado e representado numericamente. Um exemplo cl√°ssico dentro da classifica√ß√£o com texto √© a de verificar se uma avalia√ß√£o de um produto √© positiva ou negativa. Isso √© uma tarefa dentro da √°rea de An√°lise de Sentimentos, e as categorias podem variar um pouco. Nessa tarefa, pegamos o texto da avalia√ß√£o {"O produto √© muito bom!", "N√£o gostei nem um pouco"} e tentaremos classificar eles como positivos ou negativos. Como vimos antes, um classificador b√°sico √© a regress√£o log√≠stica, e ela servir√° de base para entendermos o mecanismo por tr√°s dos modelos de aprendizado supervisionado com texto.


## Classifica√ß√£o com Regress√£o Log√≠stica

No ISL ({cite}`james2023introduction`.), os autores explicam a Regress√£o Log√≠stica por uma linguamge mais estat√≠stica. J√° Jurafsky e Martin ({cite}`jurafsky2024speech`.) v√£o por uma linha mais do Aprendizado de M√°quina. Por isso, n√£o estranhem a mudan√ßa de jarg√£o e de termos para se referir √† Regress√£o Log√≠stica. 

### Fun√ß√£o Sigm√≥ide

Como dito antes, o objetivo da regress√£o log√≠stica bin√°ria √© treinar um classificador capaz de tomar uma decis√£o bin√°ria sobre a classe de uma nova observa√ß√£o de entrada. Aqui introduzimos o classificador sigmoide, que nos ajudar√° a tomar essa decis√£o. Em Jurafsky e Martin, a Regress√£o log√≠stica resolve o problema de estimar $Pr(Y=1|X)$ (A probabilidade de que a observa√ß√£o pertence √† classe 1, dado os preditores) estimando um vetor de **pesos** e **termos de vi√©s**. Vamos chamar os pesos de $w$ e o vi√©s de $b$. Cada peso $w_i$ √© um n√∫mero real e est√° associado √† um dos preditores $X_i$. O peso representa qu√£o importante √© cada preditor para a decis√£o de classifica√ß√£o, podendo ser negativo ou positivo. Em uma tarefa de classifica√ß√£o de sentimento, prov√°velmente a palavra "√≥timo" ter√° um peso positivo, e a palavra "horr√≠vel" ter√° um peso negativo. O termo de vi√©s, ou intercepto, √© um n√∫mero real que √© adicionado aos *inputs* ao final do c√°lculo. Para fazer uma decis√£o em uma observa√ß√£o de teste (ap√≥s o treinamento), o classificador log√≠stico vai multiplicar cada preditor $X_i$ pelo seu peso $w_i$, e somar isso com o termo de vi√©s. Formalmente, temos:

$$
z \;=\; \left(\sum_{i=1}^{n} w_i x_i\right) + b
$$

No entanto, os valores de $z$ resultantes dessa equa√ß√£o n√£o est√£o obrigatoriamente entre 0 e 1. Para que possamos calcular a probabilidade de que uma observa√ß√£o √© da classe 0 ou 1, precisamos limitar z para esse intervalo. Para isso, passaremos z pela fun√ß√£o sigm√≥ide $\sigma$, ou fun√ß√£o log√≠stica. Com isso, conseguiremos obter probabilidades para cada classe entre 0 e 1.

$$
\sigma(z)
   \;=\;
   \frac{1}{1 + e^{-z}}
   \;=\;
   \frac{1}{1 + \exp(-z)}
$$

 A {numref}`Figura {number} <sigmoide>` ilustra como a fun√ß√£o sigm√≥ide mapeia os valores de z para que fiquem entre 0 e 1.


```{figure} ../aula7/images/fig4.1.png
---
width: 100%
name: sigmoide
align: center
---
Fun√ß√£o sigm√≥ide. Fonte: Jurafsky e Martin (2025, {cite}`jurafsky2024speech`.)
```

Com a fun√ß√£o sigm√≥ide, conseguimos computar a probabilidade $Pr(y=1|X)$. No entanto, precisamos tamb√©m definir um n√≠vel de decis√£o. Para uma probabilidade de 0.51, classificaremos a observa√ß√£o como da classe 1 ou da classe 0? Apesar de bem pr√≥ximo ao meio termo, poder√≠amos adotar o n√≠vel de decis√£o de 0.5, o que jogaria essa observa√ß√£o para classe 1. Isso √© o que √© conhecido no aprendizado de m√°quina como *Decision Boundary*.

$$
\operatorname{decision}(x)=
\begin{cases}
1 & \text{se } P\!\bigl(y=1 \mid x\bigr) > 0.5 \\
0 & \text{caso contr√°rio}
\end{cases}
$$

Resumindo, o processo de classifica√ß√£o com a regress√£o log√≠stica √© o seguinte: Estimamos um valor $z$ utilizando os pesos e termo de vi√©s estimados pelo classificador durante o treinamento. Passamos cada z pela fun√ß√£o sigm√≥ide, mapeando-os para um valor no intervalo [0,1]. Com um n√≠vel de decis√£o definidos pelo pesquisador (ou o padr√£o do classificador), pegamos a probabilidade estimada e classificamos cada observa√ß√£o de teste entre as classes 0 ou 1. A {numref}`Figura {number} <logclass>` mostra como a regress√£o log√≠stica calcula a probabilidade de uma observa√ß√£o ser de uma classe dada as *features* de texto.



```{figure} ../aula7/images/fig4.3.1.png
---
width: 100%
name: logclass
align: center
---
Classifica√ß√£o na regress√£o Log√≠stica Bin√°ria. Fonte: Jurafsky e Martin (2025, {cite}`jurafsky2024speech`.)
```

## Classifica√ß√£o com Regress√£o Multinomial

Quando temos un n√∫mero de classes $K>2$, n√£o podemos utilizar a regress√£o log√≠stica ou a fun√ß√£o sigm√≥ide. Portanto, para o caso da regress√£o multinomial, utilizamos outra fun√ß√£o que permite mapear os valores estimados $z$ para probabilidades que podem ser usadas para decidir a classe de uma observa√ß√£o, a fun√ß√£o ***Softmax***.

### Fun√ß√£o Softmax



```{video} https://www.youtube.com/embed/KpKog-L9veg?si=my4iOKA4GkFuMT6U
```

---

A fun√ß√£o **Softmax** √© uma generaliza√ß√£o da fun√ß√£o Sigm√≥ide, usada no modelo de regress√£o multinomial para calcular a probabilidade de que as observa√ß√µes pertencem a uma classe k $Pr(Y = k | X)$. A fun√ß√£o *softmax* pegar um vetor $\mathbf{z} = [z_1, z_2, ..., z_k]$ das probabilidades de cada classe para $k$ classes e mapeia cada uma para uma distribui√ß√£o de probabilidades, dentro do intervalo [0,1] e somando 1 ao total. Para um vetor $\mathbf{z}$ de dimensionalidade K, o softmax √© definido como:

$$
\operatorname{softmax}(z_i)
   \;=\;
   \frac{\exp\!\bigl(z_i\bigr)}
        {\displaystyle\sum_{j=1}^{K}\exp\!\bigl(z_j\bigr)}
   \quad\text{para } 1 \le i \le K
$$

E o *softmax* para de um vetor de entrada $\mathbf{z}$ tamb√©m ser√° ele mesmo um vetor:

$$
\operatorname{softmax}(\mathbf{z})
   \;=\;
   \Biggl[
      \frac{\exp\!\bigl(z_1\bigr)}{\displaystyle\sum_{i=1}^{K}\exp\!\bigl(z_i\bigr)},
      \;
      \frac{\exp\!\bigl(z_2\bigr)}{\displaystyle\sum_{i=1}^{K}\exp\!\bigl(z_i\bigr)},
      \; \dots,\;
      \frac{\exp\!\bigl(z_K\bigr)}{\displaystyle\sum_{i=1}^{K}\exp\!\bigl(z_i\bigr)}
   \Biggr]
$$

Por meio dessa fun√ß√£o, podemos estimar as probabilidades de que uma observa√ß√£o perten√ßa a cada uma das classes num contexto de $K$ classes. Por exemplo, poder√≠amos ter o seguinte softmax para uma observa√ß√£o de teste em uma classifica√ß√£o com 6 classes:

$$
[0.05, 0.09, 0.01, 0.1, 0.74, 0.01]
$$

Nessa situa√ß√£o temos que a probabilidade de que a observa√ß√£o seja classificada com da classe de n√∫mero 5 √© de 74% (0.74), e sabemos tamb√©m os valores estimados para todas as outras classes (e.g. classe 1 = 0.05, etc). A {numref}`Figura {number} <multclass>` mostra como a regress√£o multinomial calcula as probabilidades de uma observa√ß√£o ser de uma classe dada as *features* de texto.



```{figure} ../aula7/images/fig4.3.2.png
---
width: 100%
name: multclass
align: center
---
Classifica√ß√£o na regress√£o Multinomial. Fonte: Jurafsky e Martin (2025, {cite}`jurafsky2024speech`.)
```




## O aprendizado na Regress√£o Log√≠stica/Multinomial

Como os par√¢metros do modelo log√≠stico, os pesos $\mathbf{w}$ e o vi√©s b, s√£o estimados? Precisamos de dois componentes principais para essa estimativa: Uma m√©trica do qu√£o distante os r√≥tulos previstos $\hat{y}$ est√£o do valor verdadeiro de $y$. Essa dist√¢ncia √© mensurada por meio de uma **fun√ß√£o de perda** (*Loss/Cost Function*). Um segundo componente √© um **algoritmo de otimiza√ß√£o** para atualizarmos os pesos iterativamente para reduzir a fun√ß√£o de perda ao m√°ximo. Um algoritmo comumente usado √© o *Gradient Descent*. Veremos agora uma fun√ß√£o de perda comum (*Cross-Entropy*) e o *Gradient Descent*.

### A fun√ß√£o de Perda *Cross-entropy*


```{video} https://www.youtube.com/embed/6ArSys5qHAU?si=qVH8W4n4xPbCNmMX
```
--- 

Precisamos de uma fun√ß√£o de perda que expresse, para uma observa√ß√£o, o qu√£o pr√≥ximo uma sa√≠da do classificador $\hat{y} = \mathbf{\sigma} (\mathbf{w}*\mathbf{x} + b) $ √© em rela√ß√£o ao valor correto de base, $Y$. Formalizando, queremos descobrir

$$
L(\hat{y},y)
$$

Que √© quanto $\hat{y}$ difere de $y$. Fazemos isso por meio de uma fun√ßa√µ de perda que vai preferir que a classifica√ß√£o correta durante o treinamento seja a mais prov√°vel. Isso √© conhecido como *MLE* condicional: escolhemos os par√¢metros $w,b$ que maximizam a probabilidade dos valores verdadeiros de y dados os valores x de treinamento. A fun√ß√£o de perda resultate √© a *negative log likelihood loss*, mais conhecida como ***Cross-Entropy Loss***.


### Descida do Gradiente

```{video} https://www.youtube.com/embed/IHZwWFHWa-w?si=FMtTFGir0x5qFyCX
```
---

O objetivo da descida do gradiente (*Gradient Descent*) √© achar os pesos √≥timos, minimizando nossa fun√ß√£o de perda para todas as observa√ß√µes. Como podemos achar o m√≠nimo dessa fun√ß√£o? O m√©todo da descida do gradiente procura o m√≠nimo da fun√ß√£o descobrindo em qual dire√ß√£o (dentro do espa√ßo de par√¢metros) a inclina√ß√£o da fun√ß√£o est√° aumentando mais rapidamente, e ent√£o se move na dire√ß√£o contr√°ria. No caso da regress√£o log√≠stica (ou multinomial), estamos navegando um espa√ßo de par√¢metros 2D: Temos o peso $w$ e navegamos ele ao longo da fun√ß√£o de perda. Em modelos mais complexos, como os de redes neurais, o espa√ßo de par√¢metros passa a ter mais dimens√µes.  A {numref}`Figura {number} <gradientdesc>` mostra como o algortimo de otimiza√ß√£o percorre a fun√ß√£o de perda para tentar encontrar o m√≠nimo global, reduzindo a fun√ß√£o de perda e garantindo melhores previs√µes do modelo de aprendizado supervisionado.


```{figure} ../aula7/images/fig4.5.png
---
width: 100%
name: gradientdesc
align: center
---
Movimenta√ß√£o do Algoritmo de Otimiza√ß√£o. Fonte: Jurafsky e Martin (2025, {cite}`jurafsky2024speech`.)
```

O algoritmo de descida do gradiente procura o gradiente da fun√ß√£o de perda no ponto atual e se move na dire√ß√£o contr√°ria. Podemos pensar no gradiente como a inclina√ß√£o da reta (reta pontilhada verde na figura), na situa√ß√£o de uma √∫nica vari√°vel de otimiza√ß√£o. A velocidade desse "passo" da descida do gradiente ser√° ditada por um hiperpar√¢metro[^1], a **Taxa de Aprendizado**.

### Taxa de Aprendizado

Quanto o algoritmo de otimiza√ß√£o vai se "mexer" a cada itera√ß√£o da descida do gradiente vai depender da **Taxa de Aprendizado**, ou *Learning Rate*. Uma alta taxa de aprendizado faz com que o algoritmo de um "passo" maior, se movendo mais ao longo da curva de aprendizado (Loss x Weights). Isso faz com que o modelo treine mais rapidamente mas, em contextos de aprendizado profundo, pode ser que ele fique em um m√≠nimo local, n√£o minimizando o erro ao m√°ximo. Inversamente, uma taxa de aprendizado baixa faz com que o modelo precise de mais itera√ß√µes para definir um m√≠nimo, mas n√£o garante que ele vai chegar no m√≠nimo global.


```{admonition} üí¨ Com a palavra, os autores:
:class: quote
"A taxa de aprendizado Œ∑ √© um hiperpar√¢metro que precisa ser ajustado. Se for muito alta, o modelo dar√° passos excessivamente grandes e ultrapassar√° o m√≠nimo da fun√ß√£o de perda; se for muito baixa, dar√° passos muito pequenos e demorar√° para chegar ao m√≠nimo. √â comum come√ßar com uma taxa de aprendizado maior e reduzi-la gradualmente, fazendo-a variar com a itera√ß√£o k do treinamento."
({cite}`jurafsky2024speech`., p. 77, tradu√ß√£o nossa)
```




## Notas

[^1]: Hiperpar√¢metro √© uma vari√°vel de configura√ß√£o definida manualmente antes do treinamento que controla aspectos essenciais de como o algoritmo de machine learning aprende, como a taxa de aprendizado, o n√∫mero de camadas de uma rede neural ou o tamanho do lote de dados. Diferentemente dos par√¢metros do modelo (pesos e vieses), que s√£o ajustados automaticamente pelo processo de otimiza√ß√£o, os hiperpar√¢metros precisam ser escolhidos e refinados pelo pesquisador ‚Äî pr√°tica conhecida como ajuste (ou otimiza√ß√£o) de hiperpar√¢metros ‚Äî porque influenciam diretamente a velocidade de converg√™ncia, a capacidade de generaliza√ß√£o e o risco de sobreajuste do modelo.


